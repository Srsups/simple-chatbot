quarkus.datasource.db-kind=h2
quarkus.datasource.jdbc.url=jdbc:h2:mem:tarefasdb;DB_CLOSE_DELAY=-1
quarkus.datasource.username=sa
quarkus.datasource.password=password
quarkus.hibernate-orm.database.generation=drop-and-create

# CORS - Configuração permissiva para desenvolvimento
quarkus.http.cors=true
quarkus.http.cors.origins=*
quarkus.http.cors.methods=GET,PUT,POST,DELETE,OPTIONS
quarkus.http.cors.headers=Content-Type,Authorization

# URL oficial do GitHub Models (compatível com OpenAI)
quarkus.langchain4j.openai.base-url=https://models.inference.ai.azure.com

# Seu token Fine-grained (github_pat_...)
quarkus.langchain4j.openai.api-key=${MY_GITHUB_TOKEN}

# Nome EXATO do modelo escolhido no Marketplace
# Exemplos: "gpt-4o", "Llama-3.3-70B-Instruct", "Mistral-large"
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o

# (Opcional) Aumente o timeout pois modelos gratuitos podem ter "fila"
quarkus.langchain4j.openai.timeout=60s

# Mantém o log para você ver se conectou certo
quarkus.langchain4j.openai.log-requests=true
quarkus.langchain4j.openai.log-responses=true

# --- MANTENHA A CONFIGURAÇÃO DO EMBEDDING LOCAL ---
# Não mude isso, pois o GitHub Models foca em geração de texto (chat), 
# e nós continuamos usando o processamento local para ler o CSV (é mais rápido e grátis).
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.allminilml6v2.AllMiniLmL6V2EmbeddingModel